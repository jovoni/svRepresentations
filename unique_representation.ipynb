{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovoni/anaconda3/envs/dnabert/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, DNATokenizer\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_tokenizer(s, tokenizer):\n",
    "    out = tokenizer.encode(\n",
    "                        s,\n",
    "                        add_special_tokens = True,  # Add '[CLS]' and '[SEP]'\n",
    "                        padding = 'longest',        # Pad to longest in batch.\n",
    "                        truncation = True,          # Truncate sentences to `max_length`.\n",
    "                        max_length = 512,   \n",
    "                        return_attention_mask = True, # Construct attn. masks.\n",
    "                        return_tensors = 'pt',        # Return pytorch tensors.\n",
    "                )\n",
    "    return out\n",
    "\n",
    "def obtain_embeddings(s, model, tokenizer):\n",
    "    tokenizer_output = feed_tokenizer(s, tokenizer)\n",
    "    model_output = model(tokenizer_output)\n",
    "    hidden_states = model_output[1]\n",
    "\n",
    "    # Create tensor of embeddings\n",
    "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "    token_embeddings = token_embeddings.squeeze()\n",
    "    return token_embeddings.detach().numpy()\n",
    "\n",
    "def obtain_sentence_representations(embeddings, kind):\n",
    "    assert len(embeddings.shape) == 3\n",
    "    \n",
    "    representations = []\n",
    "    \n",
    "    for layer_emb in embeddings:\n",
    "        if kind == \"mean\":\n",
    "            r = np.mean(layer_emb, axis=0)\n",
    "        elif kind == \"sum\":\n",
    "            r = np.sum(layer_emb, axis=0)\n",
    "        else:\n",
    "            raise Exception\n",
    "        representations.append(r)\n",
    "        \n",
    "    return representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "<class 'transformers.tokenization_dna.DNATokenizer'>\n"
     ]
    }
   ],
   "source": [
    "# Info\n",
    "model_path = \"dnabert6/\"\n",
    "\n",
    "# Load config, model and tokenizer\n",
    "tokenizer = DNATokenizer.from_pretrained(model_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path, \n",
    "                                                    output_attentions=True,\n",
    "                                                    output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "metadata = pd.read_csv(\"dataset/same_sequence/all_data_0.csv\", sep=\";\")\n",
    "data = pd.read_csv(\"dataset/same_sequence/data_0.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:56<00:00,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "sequences = data.sequence.values\n",
    "\n",
    "R = []\n",
    "layer = -1\n",
    "\n",
    "for s in tqdm(sequences):\n",
    "    emb = obtain_embeddings(s, model, tokenizer)\n",
    "    representations = obtain_sentence_representations(emb, \"mean\")\n",
    "    R.append(representations[layer])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnabert",
   "language": "python",
   "name": "dnabert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
